{"ast":null,"code":"\"use strict\";\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n/*\n  The MIT License\n  \n  Copyright (c) 2017-2019 EclipseSource Munich\n  https://github.com/eclipsesource/jsonforms\n  \n  Permission is hereby granted, free of charge, to any person obtaining a copy\n  of this software and associated documentation files (the \"Software\"), to deal\n  in the Software without restriction, including without limitation the rights\n  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n  copies of the Software, and to permit persons to whom the Software is\n  furnished to do so, subject to the following conditions:\n  \n  The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n  \n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n  THE SOFTWARE.\n*/\n\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\n\nvar get_1 = __importDefault(require(\"lodash/get\"));\n\nvar isArray_1 = __importDefault(require(\"lodash/isArray\"));\n\nvar isObject_1 = __importDefault(require(\"lodash/isObject\"));\n\nvar isFunction_1 = __importDefault(require(\"lodash/isFunction\"));\n\nvar isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\n\nvar forOwn_1 = __importDefault(require(\"lodash/forOwn\"));\n\nvar isString_1 = __importDefault(require(\"lodash/isString\"));\n\nvar isPlainObject_1 = __importDefault(require(\"lodash/isPlainObject\"));\n\nvar uri_js_1 = require(\"uri-js\");\n\nvar isObjectSchema = function isObjectSchema(schema) {\n  return schema.properties !== undefined;\n};\n\nvar isArraySchema = function isArraySchema(schema) {\n  return schema.type === 'array' && schema.items !== undefined;\n};\n\nexports.resolveData = function (instance, dataPath) {\n  if (isEmpty_1.default(dataPath)) {\n    return instance;\n  }\n\n  var dataPathSegments = dataPath.split('.');\n  return dataPathSegments.map(function (segment) {\n    return decodeURIComponent(segment);\n  }).reduce(function (curInstance, decodedSegment) {\n    if (curInstance === undefined || !curInstance.hasOwnProperty(decodedSegment)) {\n      return undefined;\n    }\n\n    return curInstance[decodedSegment];\n  }, instance);\n};\n/**\n * Finds all references inside the given schema.\n *\n * @param schema The {@link JsonSchema} to find the references in\n * @param result The initial result map, default: empty map (this parameter is used for recursion\n *               inside the function)\n * @param resolveTuples Whether arrays of tuples should be considered; default: false\n */\n\n\nexports.findAllRefs = function (schema, result, resolveTuples) {\n  if (result === void 0) {\n    result = {};\n  }\n\n  if (resolveTuples === void 0) {\n    resolveTuples = false;\n  }\n\n  if (isObjectSchema(schema)) {\n    Object.keys(schema.properties).forEach(function (key) {\n      return exports.findAllRefs(schema.properties[key], result);\n    });\n  }\n\n  if (isArraySchema(schema)) {\n    if (Array.isArray(schema.items)) {\n      if (resolveTuples) {\n        var items = schema.items;\n        items.forEach(function (child) {\n          return exports.findAllRefs(child, result);\n        });\n      }\n    } else {\n      exports.findAllRefs(schema.items, result);\n    }\n  }\n\n  if (Array.isArray(schema.anyOf)) {\n    var anyOf = schema.anyOf;\n    anyOf.forEach(function (child) {\n      return exports.findAllRefs(child, result);\n    });\n  }\n\n  if (schema.$ref !== undefined) {\n    result[schema.$ref] = schema;\n  }\n\n  return result;\n};\n/**\n * Resolve the given schema path in order to obtain a subschema.\n * @param {JsonSchema} schema the root schema from which to start\n * @param {string} schemaPath the schema path to be resolved\n * @param {JsonSchema} rootSchema the actual root schema\n * @returns {JsonSchema} the resolved sub-schema\n */\n\n\nexports.resolveSchema = function (schema, schemaPath, rootSchema) {\n  if (isEmpty_1.default(schema)) {\n    return undefined;\n  }\n\n  var validPathSegments = schemaPath.split('/');\n\n  var invalidSegment = function invalidSegment(pathSegment) {\n    return pathSegment === '#' || pathSegment === undefined || pathSegment === '';\n  };\n\n  var resultSchema = validPathSegments.reduce(function (curSchema, pathSegment) {\n    curSchema = curSchema === undefined || curSchema.$ref === undefined ? curSchema : exports.resolveSchema(schema, curSchema.$ref);\n    return invalidSegment(pathSegment) ? curSchema : get_1.default(curSchema, pathSegment);\n  }, schema); // TODO: because schema is already scoped we might end up with refs pointing\n  // outside of the current schema. It would be better if we'd always could deal\n  // with absolute paths here, so that we don't need to keep two different\n  // schemas around\n\n  if (resultSchema !== undefined && resultSchema.$ref !== undefined) {\n    try {\n      return retrieveResolvableSchema(schema, resultSchema.$ref);\n    } catch (e) {\n      return retrieveResolvableSchema(rootSchema, resultSchema.$ref);\n    }\n  }\n\n  return resultSchema;\n};\n/**\n * Normalizes the schema and resolves the given ref.\n *\n * @param {JsonSchema} full the JSON schema to resolved the reference against\n * @param {string} reference the reference to be resolved\n * @returns {JsonSchema} the resolved sub-schema\n */\n// disable rule because resolve is mutually recursive\n// tslint:disable:only-arrow-functions\n\n\nfunction retrieveResolvableSchema(full, reference) {\n  // tslint:enable:only-arrow-functions\n  var child = exports.resolveSchema(full, reference);\n  var allRefs = exports.findAllRefs(child);\n  var innerSelfReference = allRefs[reference];\n\n  if (innerSelfReference !== undefined) {\n    innerSelfReference.$ref = '#';\n  }\n\n  return child;\n}\n\nexports.findRefs = function (obj) {\n  var refs = {}; // Walk the document (or sub document) and find all JSON References\n\n  walk([], obj, [], function (_a, node, path) {\n    var processChildren = true;\n    var refDetails;\n    var refPtr;\n\n    if (isRefLike(node, false)) {\n      refDetails = getRefDetails(node);\n\n      if (refDetails.type !== 'invalid') {\n        refPtr = pathToPtr(path, undefined);\n        refs[refPtr] = refDetails;\n      } // Whenever a JSON Reference has extra children, its children should not be processed.\n      //   See: http://tools.ietf.org/html/draft-pbryan-zyp-json-ref-03#section-3\n\n\n      if (getExtraRefKeys(node).length > 0) {\n        processChildren = false;\n      }\n    }\n\n    return processChildren;\n  });\n  return refs;\n}; // pure copy of JsonRefs (added types)\n\n\nvar walk = function walk(ancestors, node, path, fn) {\n  var processChildren = true;\n\n  var walkItem = function walkItem(item, segment) {\n    path.push(segment);\n    walk(ancestors, item, path, fn);\n    path.pop();\n  }; // Call the iteratee\n\n\n  if (isFunction_1.default(fn)) {\n    processChildren = fn(ancestors, node, path);\n  } // We do not process circular objects again\n\n\n  if (ancestors.indexOf(node) === -1) {\n    ancestors.push(node);\n\n    if (processChildren !== false) {\n      if (isArray_1.default(node)) {\n        node.forEach(function (member, index) {\n          walkItem(member, index.toString());\n        });\n      } else if (isObject_1.default(node)) {\n        forOwn_1.default(node, function (cNode, key) {\n          walkItem(cNode, key);\n        });\n      }\n    }\n\n    ancestors.pop();\n  }\n};\n\nvar pathToPtr = function pathToPtr(path, hashPrefix) {\n  if (!isArray_1.default(path)) {\n    throw new Error('path must be an Array');\n  } // Encode each segment and return\n\n\n  return (hashPrefix !== false ? '#' : '') + (path.length > 0 ? '/' : '') + encodePath(path).join('/');\n};\n\nvar encodePath = function encodePath(path) {\n  if (!isArray_1.default(path)) {\n    throw new TypeError('path must be an array');\n  }\n\n  return path.map(function (seg) {\n    if (!isString_1.default(seg)) {\n      seg = JSON.stringify(seg);\n    }\n\n    return seg.replace(/~/g, '~0').replace(/\\//g, '~1');\n  });\n};\n\nvar uriDetailsCache = {};\nvar badPtrTokenRegex = /~(?:[^01]|$)/g;\n\nvar getRefDetails = function getRefDetails(obj) {\n  var details = {\n    def: obj\n  };\n  var cacheKey;\n  var extraKeys;\n  var uriDetails;\n\n  try {\n    if (isRefLike(obj, true)) {\n      cacheKey = obj.$ref;\n      uriDetails = uriDetailsCache[cacheKey];\n\n      if (isUndefined_1.default(uriDetails)) {\n        uriDetails = uriDetailsCache[cacheKey] = parseURI(cacheKey);\n      }\n\n      details.uri = cacheKey;\n      details.uriDetails = uriDetails;\n\n      if (isUndefined_1.default(uriDetails.error)) {\n        details.type = getRefType(details); // Validate the JSON Pointer\n\n        try {\n          if (['#', '/'].indexOf(cacheKey[0]) > -1) {\n            isPtr(cacheKey, true);\n          } else if (cacheKey.indexOf('#') > -1) {\n            isPtr(uriDetails.fragment, true);\n          }\n        } catch (err) {\n          details.error = err.message;\n          details.type = 'invalid';\n        }\n      } else {\n        details.error = details.uriDetails.error;\n        details.type = 'invalid';\n      } // Identify warning\n\n\n      extraKeys = getExtraRefKeys(obj);\n\n      if (extraKeys.length > 0) {\n        details.warning = 'Extra JSON Reference properties will be ignored: ' + extraKeys.join(', ');\n      }\n    } else {\n      details.type = 'invalid';\n    }\n  } catch (err) {\n    details.error = err.message;\n    details.type = 'invalid';\n  }\n\n  return details;\n};\n\nvar getRefType = function getRefType(refDetails) {\n  var type; // Convert the URI reference to one of our types\n\n  switch (refDetails.uriDetails.reference) {\n    case 'absolute':\n    case 'uri':\n      type = 'remote';\n      break;\n\n    case 'same-document':\n      type = 'local';\n      break;\n\n    default:\n      type = refDetails.uriDetails.reference;\n  }\n\n  return type;\n};\n\nvar getExtraRefKeys = function getExtraRefKeys(ref) {\n  return Object.keys(ref).filter(function (key) {\n    return key !== '$ref';\n  });\n};\n\nvar parseURI = function parseURI(uri) {\n  // We decode first to avoid doubly encoding\n  return uri_js_1.parse(uri);\n};\n\nvar isPtr = function isPtr(ptr, throwWithDetails) {\n  var valid = true;\n  var firstChar;\n\n  try {\n    if (isString_1.default(ptr)) {\n      if (ptr !== '') {\n        firstChar = ptr.charAt(0);\n\n        if (['#', '/'].indexOf(firstChar) === -1) {\n          throw new Error('ptr must start with a / or #/');\n        } else if (firstChar === '#' && ptr !== '#' && ptr.charAt(1) !== '/') {\n          throw new Error('ptr must start with a / or #/');\n        } else if (ptr.match(badPtrTokenRegex)) {\n          throw new Error('ptr has invalid token(s)');\n        }\n      }\n    } else {\n      throw new Error('ptr is not a String');\n    }\n  } catch (err) {\n    if (throwWithDetails === true) {\n      throw err;\n    }\n\n    valid = false;\n  }\n\n  return valid;\n};\n\nvar isRefLike = function isRefLike(obj, throwWithDetails) {\n  var refLike = true;\n\n  try {\n    if (!isPlainObject_1.default(obj)) {\n      throw new Error('obj is not an Object');\n    } else if (!isString_1.default(obj.$ref)) {\n      throw new Error('obj.$ref is not a String');\n    }\n  } catch (err) {\n    if (throwWithDetails) {\n      throw err;\n    }\n\n    refLike = false;\n  }\n\n  return refLike;\n};","map":null,"metadata":{},"sourceType":"script"}